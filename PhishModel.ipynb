{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Loading\n",
    "\n",
    "phish_data = pd.read_csv('dataset/phishing_site_urls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 URL Label\n0  nobell.it/70ffb52d079109dca5664cce6f317373782/...   bad\n1  www.dghjdgf.com/paypal.co.uk/cycgi-bin/webscrc...   bad\n2  serviciosbys.com/paypal.cgi.bin.get-into.herf....   bad\n3  mail.printakid.com/www.online.americanexpress....   bad\n4  thewhiskeydregs.com/wp-content/themes/widescre...   bad",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>URL</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>nobell.it/70ffb52d079109dca5664cce6f317373782/...</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>www.dghjdgf.com/paypal.co.uk/cycgi-bin/webscrc...</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>serviciosbys.com/paypal.cgi.bin.get-into.herf....</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mail.printakid.com/www.online.americanexpress....</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>thewhiskeydregs.com/wp-content/themes/widescre...</td>\n      <td>bad</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                       URL Label\n549341     23.227.196.215/   bad\n549342  apple-checker.org/   bad\n549343   apple-iclods.org/   bad\n549344  apple-uptoday.org/   bad\n549345   apple-search.info   bad",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>URL</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>549341</th>\n      <td>23.227.196.215/</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>549342</th>\n      <td>apple-checker.org/</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>549343</th>\n      <td>apple-iclods.org/</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>549344</th>\n      <td>apple-uptoday.org/</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>549345</th>\n      <td>apple-search.info</td>\n      <td>bad</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_data.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          URL  Label\n0       False  False\n1       False  False\n2       False  False\n3       False  False\n4       False  False\n...       ...    ...\n549341  False  False\n549342  False  False\n549343  False  False\n549344  False  False\n549345  False  False\n\n[549346 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>URL</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>549341</th>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>549342</th>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>549343</th>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>549344</th>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>549345</th>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>549346 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1098692"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[39], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#Lets use Tokenizer first to gather words\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# then use countVectorizer to Vectorize all words\u001B[39;00m\n\u001B[0;32m      4\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m RegexpTokenizer(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[A-Za-z]+\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m phish_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext_tokenized\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mphish_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mURL\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\PhishMLmodel-7CoL9bgq\\lib\\site-packages\\pandas\\core\\series.py:4539\u001B[0m, in \u001B[0;36mSeries.map\u001B[1;34m(self, arg, na_action)\u001B[0m\n\u001B[0;32m   4460\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap\u001B[39m(\n\u001B[0;32m   4461\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4462\u001B[0m     arg: Callable \u001B[38;5;241m|\u001B[39m Mapping \u001B[38;5;241m|\u001B[39m Series,\n\u001B[0;32m   4463\u001B[0m     na_action: Literal[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   4464\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Series:\n\u001B[0;32m   4465\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4466\u001B[0m \u001B[38;5;124;03m    Map values of Series according to an input mapping or function.\u001B[39;00m\n\u001B[0;32m   4467\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4537\u001B[0m \u001B[38;5;124;03m    dtype: object\u001B[39;00m\n\u001B[0;32m   4538\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4539\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4540\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(new_values, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex)\u001B[38;5;241m.\u001B[39m__finalize__(\n\u001B[0;32m   4541\u001B[0m         \u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmap\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4542\u001B[0m     )\n",
      "File \u001B[1;32m~\\.virtualenvs\\PhishMLmodel-7CoL9bgq\\lib\\site-packages\\pandas\\core\\base.py:890\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[1;34m(self, mapper, na_action)\u001B[0m\n\u001B[0;32m    887\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m    889\u001B[0m \u001B[38;5;66;03m# mapper is a function\u001B[39;00m\n\u001B[1;32m--> 890\u001B[0m new_values \u001B[38;5;241m=\u001B[39m \u001B[43mmap_f\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    892\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m new_values\n",
      "File \u001B[1;32m~\\.virtualenvs\\PhishMLmodel-7CoL9bgq\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn[39], line 5\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#Lets use Tokenizer first to gather words\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# then use countVectorizer to Vectorize all words\u001B[39;00m\n\u001B[0;32m      4\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m RegexpTokenizer(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[A-Za-z]+\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m phish_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext_tokenized\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m phish_data\u001B[38;5;241m.\u001B[39mURL\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m t: \u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#Lets use Tokenizer first to gather words\n",
    "# then use countVectorizer to Vectorize all words\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'[A-Za-z]+')\n",
    "phish_data['text_tokenized'] = phish_data.URL.map(lambda t: tokenizer.tokenize(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Snow Ball Streamer for getting root words\n",
    "\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "phish_data['text_stemmed'] = phish_data['text_tokenized'].map(lambda l:\n",
    "                                                              [stemmer.stem(word) for word in l])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the stemmed text corpus\n",
    "\n",
    "phish_data['text_sent'] = phish_data['text_stemmed'].map(lambda l: ' '.join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Count Vectorization to vectorize the text corpus\n",
    "\n",
    "cv = CountVectorizer()\n",
    "feature = cv.fit_transform(phish_data['text_sent'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Spliting training data and testing data\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(feature, phish_data.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Using Logistic Regression to train the model\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(trainX, trainY)\n",
    "print(lr.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Used to Predict the user input\n",
    "\n",
    "def user_data_predict(user_data):\n",
    "    res = lr.predict(user_data)[0]\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes User Input and applies data pre-processing\n",
    "# tasks before predicting\n",
    "\n",
    "def user_input(data):\n",
    "    tk_data = tokenizer.tokenize(data)\n",
    "    stm_data = None\n",
    "    join_data = []\n",
    "    for word in tk_data:\n",
    "        stm_data = stemmer.stem(word)\n",
    "        join_data.append(stm_data)\n",
    "    join_data = ' '.join(join_data)\n",
    "    print(join_data)\n",
    "    user_data = cv.transform([join_data])\n",
    "    res = user_data_predict(user_data)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\N.K.Rahul\\.virtualenvs\\PhishMLmodel-7CoL9bgq\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\N.K.Rahul\\.virtualenvs\\PhishMLmodel-7CoL9bgq\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9668770979415598\n"
     ]
    }
   ],
   "source": [
    "# Pipelining the code\n",
    "\n",
    "pipeline_lr = make_pipeline(CountVectorizer(tokenizer = RegexpTokenizer(r'[A-Za-z]+').tokenize,stop_words='english'), LogisticRegression())\n",
    "trainX, testX, trainY, testY = train_test_split(phish_data.URL, phish_data.Label)\n",
    "pipeline_lr.fit(trainX,trainY)\n",
    "print(pipeline_lr.score(testX,testY) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling the model\n",
    "pickle.dump(pipeline_lr,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b89494c1af638d28ebc834529db2f309ec78981a7a734b2052af15917f03ce26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}